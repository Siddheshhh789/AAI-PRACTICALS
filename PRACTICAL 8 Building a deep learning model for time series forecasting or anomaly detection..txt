import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# 1. Prepare and normalize data
data = pd.DataFrame(np.sin(np.linspace(0, 100, 1000)), columns=['value'])
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

# 2. Create dataset for LSTM (use the last 10 data points to predict the next)
X, y = [], []
for i in range(len(scaled_data) - 10):
    X.append(scaled_data[i:i+10, 0])  # Input sequence (previous 10 points)
    y.append(scaled_data[i+10, 0])   # Output value (next point)
X, y = np.array(X), np.array(y)

# Reshape X for LSTM (samples, time steps, features)
X = X.reshape(X.shape[0], X.shape[1], 1)

# 3. Split data into train and test
train_size = int(len(X) * 0.8)  # 80% for training
X_train, X_test, y_train, y_test = X[:train_size], X[train_size:], y[:train_size], y[train_size:]

# 4. Build and train model
model = Sequential([
    LSTM(50, input_shape=(X_train.shape[1], 1)),  # 50 LSTM units
    Dense(1)  # Output layer
])

model.compile(optimizer='adam', loss='mse')

# Train the model with validation data to monitor overfitting
model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1, validation_data=(X_test, y_test))

# 5. Predict and plot results
predictions = model.predict(X_test)
predictions = scaler.inverse_transform(predictions)  # Reverse normalization of predictions
y_test = scaler.inverse_transform(y_test.reshape(-1, 1))  # Reverse normalization of y_test

# Plotting true vs predicted values
plt.figure(figsize=(10, 6))
plt.plot(y_test, label='True', color='blue')
plt.plot(predictions, label='Predicted', color='red', linestyle='--')
plt.title('Time Series Forecasting: True vs Predicted')
plt.xlabel('Time Step')
plt.ylabel('Value')
plt.legend()
plt.show()
